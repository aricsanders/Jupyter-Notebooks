{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of data translation using a bijective graph\n",
    "The graph method creates a series of interlocking nodes that have transformations between themselves. There are a few basic rules:\n",
    "1. Any node has an edge into and out of itself\n",
    "2. Any path that results in the same end location creates the same node \n",
    "\n",
    "## This example is one of a rectangular table, a set of column modeled data. \n",
    "### This graph has the folowing nodes, and hence transformations between all of them\n",
    "1. n1, 'Pandas Data Frame', in memory \n",
    "2. n2, 'AsciiDataTable', in memory\n",
    "3. n3, 'HDF File', on disk\n",
    "4. n4, 'XML Data Table',in memory\n",
    "5. n5, 'Excel File', on disk\n",
    "6. n6, 'HTML String',in memory\n",
    "7. 'JSON File', on disk\n",
    "8. 'JSON String',in memory\n",
    "9. 'CSV File', on disk\n",
    "10. 'Matlab File', on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Code.Utils.Names\n",
      "Importing Code.DataHandlers.NISTModels\n",
      "Importing Code.DataHandlers.GeneralModels\n",
      "Importing Code.DataHandlers.TouchstoneModels\n",
      "Importing Code.DataHandlers.XMLModels\n",
      "Importing Code.DataHandlers.RadiCALModels\n",
      "Importing Code.DataHandlers.ZipModels\n",
      "Importing Code.DataHandlers.Translations\n",
      "Importing Code.DataHandlers.StatistiCALModels\n",
      "Importing Code.DataHandlers.MUFModels\n",
      "Importing Code.Analysis.SParameter\n",
      "Importing Code.InstrumentControl.Instruments\n",
      "Importing Code.InstrumentControl.Experiments\n"
     ]
    }
   ],
   "source": [
    "from pyMeasure import *\n",
    "import pandas\n",
    "from scipy.io import savemat,loadmat\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "from ipywidgets import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def edge_1_to_2(in_string):\n",
    "    return in_string.splitlines()\n",
    "    \n",
    "def edge_2_to_1(string_list):\n",
    "    return string_list_collapse(string_list)\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self,**options):\n",
    "        \"\"\"Initializes the graph. The first 2 nodes and two edges forming a bijection between them are required\"\"\"\n",
    "        defaults={\"graph_name\":\"Graph\",\n",
    "                  \"node_names\":['n1','n2'],\n",
    "                  \"node_descriptions\":{'n1':\"A plain string\",\n",
    "                                       'n2':\"A list of strings with no \\\\n, created with string.splitlines()\"},\n",
    "                  \"current_node\":'n1',\n",
    "                  \"state\":[1,0],\n",
    "                  \"data\":\"This is a test string\\n it has to have multiple lines \\n and many characters 34%6\\n^\",\n",
    "                  \"edge_2_to_1\":edge_2_to_1,\n",
    "                  \"edge_1_to_2\":edge_1_to_2\n",
    "                 }\n",
    "        self.options={}\n",
    "        for key,value in defaults.iteritems():\n",
    "            self.options[key]=value\n",
    "        for key,value in options.iteritems():\n",
    "            self.options[key]=value\n",
    "        self.elements=['graph_name','node_names','node_descriptions','current_node','state','data']\n",
    "        for element in self.elements:\n",
    "            self.__dict__[element]=self.options[element]\n",
    "        self.edges=[]\n",
    "        self.edge_matrices=[]\n",
    "        self.state_matrix=np.matrix(self.state).T\n",
    "        # Add the first 2 edges, required to intialize the graph properly\n",
    "        self.add_edge(self.node_names[0],self.node_names[1],self.options[\"edge_1_to_2\"])\n",
    "        self.add_edge(self.node_names[1],self.node_names[0],self.options[\"edge_2_to_1\"])\n",
    "        \n",
    "    def set_state(self,node_name,node_data):\n",
    "        \"\"\"Sets the graph state to be the state specified by node_name, and node_data\"\"\"\n",
    "        try:\n",
    "            current_node_state_position=self.node_names.index(node_name)\n",
    "            self.current_node=node_name\n",
    "            self.data=node_data\n",
    "            self.state=[0 for i in range(len(self.node_names))]\n",
    "            self.state[current_node_state_position]=1\n",
    "            self.state_matrix=np.matrix(self.state).T\n",
    "        except:\n",
    "            print(\"Could not set the state of graph: {0}\".format(self.graph_name))\n",
    "            raise\n",
    "            \n",
    "    def add_edge(self,begin_node=None,end_node=None,edge_function=None):\n",
    "        \"\"\"Adds an edge mapping one node to another, required input is begin_node (it's name)\n",
    "        end_node, and the edge function\"\"\"\n",
    "        # check to see if edge is defined if it is increment a number\n",
    "        edge_match=re.compile(\"edge_{0}_{1}\".format(begin_node,end_node))\n",
    "        keys=self.__dict__.keys()\n",
    "        #print keys\n",
    "        iterator=0\n",
    "        for key in keys:\n",
    "            if re.match(edge_match,key):\n",
    "                iterator+=1\n",
    "        edge_name=\"edge_{0}_{1}_{2:0>3d}\".format(begin_node,end_node,iterator)\n",
    "        self.__dict__[edge_name]=edge_function\n",
    "        self.edges.append(edge_name)\n",
    "        edge_matrix=np.zeros((len(self.state),len(self.state)))\n",
    "        begin_position=self.node_names.index(begin_node)\n",
    "        end_position=self.node_names.index(end_node)\n",
    "        edge_matrix[end_position][begin_position]=1\n",
    "        edge_matrix=np.matrix(edge_matrix)\n",
    "        self.edge_matrices.append(edge_matrix)\n",
    "        \n",
    "    def move_to(self,path):\n",
    "        \"\"\"Changes the state of the graph by moving along the path specified\"\"\"\n",
    "        #print path\n",
    "        for index,edge in enumerate(path):\n",
    "            #print edge\n",
    "            edge_pattern='edge_(?P<begin_node>\\w+)_(?P<end_node>\\w+)_(?P<iterator>\\w+)'\n",
    "            match=re.match(edge_pattern,edge)\n",
    "            begin_node=match.groupdict()['begin_node']\n",
    "            end_node=match.groupdict()['end_node']\n",
    "            print(\"moving {0} -> {1}\".format(begin_node,end_node))\n",
    "            #print self.data\n",
    "            self.data=self.__dict__[edge](self.data)\n",
    "            #print self.data\n",
    "            self.current_node=match.groupdict()['end_node']\n",
    "            self.state=[0 for i in range(len(self.node_names))]\n",
    "            position=self.node_names.index(self.current_node)\n",
    "            self.state[position]=1\n",
    "            self.state_matrix=np.matrix(self.state).T\n",
    "            #print self.state\n",
    "            #print self.current_node\n",
    "            \n",
    "    def virtual_move_to(self,path):\n",
    "        \"\"\"virtual_move_to simulates moving but does not change the state of the graph\"\"\"\n",
    "        #print path\n",
    "        temp_state=self.state\n",
    "        temp_data=self.data\n",
    "        temp_current_node=self.current_node\n",
    "        temp_node_names=self.node_names\n",
    "        for index,edge in enumerate(path):\n",
    "            #print edge\n",
    "            edge_pattern='edge_(?P<begin_node>\\w+)_(?P<end_node>\\w+)_(?P<iterator>\\w+)'\n",
    "            match=re.match(edge_pattern,edge)\n",
    "            begin_node=match.groupdict()['begin_node']\n",
    "            end_node=match.groupdict()['end_node']\n",
    "            #print(\"moving {0} -> {1}\".format(begin_node,end_node))\n",
    "            #print self.data\n",
    "            temp_data=self.__dict__[edge](temp_data)\n",
    "            #print self.data\n",
    "            temp_current_node=match.groupdict()['end_node']\n",
    "            temp_state=[0 for i in range(len(temp_node_names))]\n",
    "            position=temp_node_names.index(temp_current_node)\n",
    "            temp_state[position]=1\n",
    "            #print temp_state\n",
    "            #print self.state\n",
    "            #print self.current_node  \n",
    "            \n",
    "    def __str__(self):\n",
    "        return str(self.data)\n",
    "    \n",
    "    def add_node(self,node_name,edge_into_node_begin,edge_into_node_function,edge_out_node_end,\n",
    "                 edge_out_node_function):\n",
    "        \"\"\"Adds a node to the graph. Required input is node_name (a string with no spaces), \n",
    "        a reference to an entering node,the function mapping the entering node to the new node, \n",
    "        a reference to an exiting node and the function mapping the\n",
    "        new node to the exiting node.\"\"\"\n",
    "        # first check if node into and out of node is good\n",
    "        self.node_names.append(node_name)\n",
    "        self.state.append(0)\n",
    "        self.state_matrix=np.matrix(self.state).T\n",
    "        for index,matrix in enumerate(self.edge_matrices):\n",
    "            pad_row=np.zeros((1,len(matrix)))\n",
    "            new_matrix=np.concatenate((matrix, pad_row), axis=0)\n",
    "            pad_column=np.zeros((1,len(self.node_names)))\n",
    "            new_matrix=np.concatenate((new_matrix, pad_column.T), axis=1)\n",
    "            #print(\"New matrix is :\\n{0}\".format(new_matrix))\n",
    "            self.edge_matrices[index]=new_matrix\n",
    "        self.add_edge(begin_node=node_name,end_node=edge_out_node_end,edge_function=edge_out_node_function)\n",
    "        self.add_edge(begin_node=edge_into_node_begin,end_node=node_name,edge_function=edge_into_node_function)\n",
    "    \n",
    "    def path_length(self,path,num_repeats=10):\n",
    "        \"\"\"Determines the length of a given path, currently the metric is based on the time to move to.\"\"\"\n",
    "        begin_time=datetime.datetime.now()\n",
    "        #num_repeats=100\n",
    "        for i in range(num_repeats):\n",
    "            self.virtual_move_to(path)\n",
    "        end_time=datetime.datetime.now()\n",
    "        delta_t=end_time-begin_time\n",
    "        path_length=delta_t.total_seconds()/float(num_repeats)\n",
    "        if path_length ==0.0:\n",
    "            print(\"Warning the path length is less than 1 microsecond,\" \n",
    "                  \"make sure num_repeats is high enough to measure it.\")\n",
    "        return path_length\n",
    "                \n",
    "    def is_path_valid(self,path):\n",
    "        \"\"\"Returns True if the path is valid from the current node position or False otherwise\"\"\"\n",
    "        null_state=[0 for i in range(len(self.node_names))]\n",
    "        null_state_matrix=np.matrix(null_state).T\n",
    "        new_state=np.matrix(self.state).T\n",
    "        for index,edge in enumerate(path):\n",
    "            #print index\n",
    "            #print edge\n",
    "            edge_position=self.edges.index(edge)\n",
    "            move_matrix=self.edge_matrices[edge_position]\n",
    "            #print move_matrix\n",
    "            new_state=move_matrix*new_state\n",
    "            if new_state.any()==null_state_matrix.any():\n",
    "                #print new_state\n",
    "                #print null_state_matrix\n",
    "                return False\n",
    "        return True\n",
    "            \n",
    "            \n",
    "    def get_entering_nodes(self,node): \n",
    "        \"\"\"Returns all nodes that have an edge that enter the specificed node\"\"\"\n",
    "        enter_edge_pattern=re.compile('edge_(?P<begin_node>\\w+)_{0}_(?P<iterator>\\w+)'.format(node))\n",
    "        enter_nodes=[]\n",
    "        for index,edge in enumerate(self.edges):\n",
    "            enter_match=re.match(enter_edge_pattern,edge)\n",
    "            if enter_match:\n",
    "                enter_node=enter_match.groupdict()['begin_node']\n",
    "                enter_nodes.append(enter_node)\n",
    "        return enter_nodes\n",
    "    \n",
    "    def get_entering_edges(self,node): \n",
    "        \"\"\"Returns all edges that enter the specificed node\"\"\"\n",
    "        enter_edge_pattern=re.compile('edge_(?P<begin_node>\\w+)_{0}_(?P<iterator>\\w+)'.format(node))\n",
    "        enter_edges=[]\n",
    "        for index,edge in enumerate(self.edges):\n",
    "            if re.match(enter_edge_pattern,edge):\n",
    "                enter_edges.append(edge)\n",
    "        return enter_edges\n",
    "    \n",
    "    def get_exiting_edges(self,node):\n",
    "        \"\"\"Returns all edges that exit the specificed node\"\"\"\n",
    "        exit_edge_pattern=re.compile('edge_{0}_(?P<end_node>\\w+)_(?P<iterator>\\w+)'.format(node))\n",
    "        exit_edges=[]\n",
    "        for index,edge in enumerate(self.edges):\n",
    "            if re.match(exit_edge_pattern,edge):\n",
    "                exit_edges.append(edge)\n",
    "        return exit_edges \n",
    "    \n",
    "    def get_exiting_nodes(self,node): \n",
    "        \"\"\"Returns all nodes that have an edge leaving the specificed node\"\"\"\n",
    "        exit_edge_pattern=re.compile('edge_{0}_(?P<end_node>\\w+)_(?P<iterator>\\w+)'.format(node))\n",
    "        exit_nodes=[]\n",
    "        for index,edge in enumerate(self.edges):\n",
    "            exit_match=re.match(exit_edge_pattern,edge)\n",
    "            if exit_match:\n",
    "                exit_node=exit_match.groupdict()['end_node']\n",
    "                exit_nodes.append(exit_node)\n",
    "        return exit_nodes\n",
    "    \n",
    "    def get_path(self,first_node,last_node):\n",
    "        \"\"\"Returns the first path found between first node and last node\"\"\"\n",
    "        edge_pattern=re.compile('edge_(?P<begin_node>\\w+)_(?P<end_node>\\w+)_(?P<iterator>\\w+)')\n",
    "        exit_paths=self.get_exiting_edges(first_node)\n",
    "        next_nodes=self.get_exiting_nodes(first_node)\n",
    "        #be careful here using the wrong assignment statement breaks this function \n",
    "        possible_paths=[]\n",
    "        for exit_path in exit_paths:\n",
    "            possible_paths.append([exit_path])\n",
    "        #print(\"{0} is {1}\".format('possible_paths',possible_paths))\n",
    "        for i in range(len(self.node_names)):\n",
    "            for index,path in enumerate(possible_paths):\n",
    "                last_edge=path[-1]\n",
    "                match=re.match(edge_pattern,last_edge)\n",
    "                begin_node=match.groupdict()['begin_node']\n",
    "                end_node=match.groupdict()['end_node']\n",
    "                #print next_node\n",
    "                if end_node==last_node:\n",
    "                    #print(\"The path found is {0}\".format(path))\n",
    "                    return path\n",
    "                next_possible_paths=[]\n",
    "                next_edges=self.get_exiting_edges(end_node)\n",
    "                next_nodes=self.get_exiting_nodes(end_node)\n",
    "                #print(\"{0} is {1}\".format('next_edges',next_edges))\n",
    "                for index,next_edge in enumerate(next_edges):\n",
    "                    #be careful here using the wrong assignment statement breaks this function \n",
    "                    #next_path=path is a deal breaker!! \n",
    "                    next_path=[]\n",
    "                    for edge in path:\n",
    "                        next_path.append(edge)\n",
    "                    #print(\"{0} is {1}\".format('next_path',next_path))\n",
    "                    #print(\"{0} is {1}\".format('next_edge',next_edge))\n",
    "                    #next_node=next_nodes[index]\n",
    "                    #print next_node\n",
    "                    next_match=re.match(edge_pattern,next_edge)\n",
    "                    next_node=next_match.groupdict()[\"end_node\"]\n",
    "                    begin_node_next_edge=next_match.groupdict()[\"begin_node\"]\n",
    "                    #print(\"{0} is {1}\".format('next_node',next_node))\n",
    "                    #print(\"{0} is {1}\".format('begin_node_next_edge',begin_node_next_edge))\n",
    "                    \n",
    "                    if next_node==last_node and begin_node_next_edge==end_node:\n",
    "                        next_path.append(next_edge)\n",
    "                        #print(\"The path found is {0}\".format(next_path))\n",
    "                        return next_path\n",
    "                    elif begin_node_next_edge==end_node:\n",
    "                        next_path.append(next_edge)\n",
    "                        next_possible_paths.append(next_path)\n",
    "                        #print(\"{0} is {1}\".format('next_possible_paths',next_possible_paths))\n",
    "                    else:\n",
    "                        pass\n",
    "                    #print(\"{0} is {1}\".format('next_possible_paths',next_possible_paths))\n",
    "                possible_paths=next_possible_paths\n",
    "                #print(\"{0} is {1}\".format('possible_paths',possible_paths))\n",
    "    \n",
    "    def move_to_node(self,node):\n",
    "        \"\"\"Moves from current_node to the specified node\"\"\"\n",
    "        path=self.get_path(self.current_node,node)\n",
    "        self.move_to(path)\n",
    "            \n",
    "    def check_closed_path(self):\n",
    "        \"\"\"Checks that data is not changed for the first closed path found. Returns True if data==data after\n",
    "        moving around the closed path, False otherwise. Starting point is current_node \"\"\"\n",
    "        temp_data=self.data\n",
    "        path=self.get_path(self.current_node,self.current_node)\n",
    "        if self.is_path_valid(path):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Path is not valid, graph definition is broken\")\n",
    "            raise\n",
    "        out=temp_data==self.data\n",
    "        out_list=[self.current_node,path,out]\n",
    "        print(\"The assertion that the data remains unchanged,\\n\" \n",
    "              \"for node {0} following path {1} is {2}\".format(*out_list))\n",
    "        return out \n",
    "    \n",
    "    def is_graph_isomorphic(self):\n",
    "        \"\"\"Returns True if all nodes have closed paths that preserve the data, False otherwise\"\"\"\n",
    "        out=True\n",
    "        for node in self.node_names:\n",
    "            self.move_to_node(node)\n",
    "            if not self.check_closed_path:\n",
    "                out=False\n",
    "        return out\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The self.metadata[\"Device_Id\"] variable is 700437\n"
     ]
    }
   ],
   "source": [
    "options={}\n",
    "options[\"data\"]=[[1,2,3],[4,5,6]]\n",
    "options[\"column_names\"]=['a','b','c']\n",
    "table=AsciiDataTable(None,**options)\n",
    "table=OnePortCalrepModel(os.path.join(TESTS_DIRECTORY,'700437.asc'))\n",
    "table=SNP(os.path.join(TESTS_DIRECTORY,'Solution_0.s4p'))\n",
    "data_frame=AsciiDataTable_to_DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_options={\"graph_name\":\"Rectangular Graph\",\n",
    "                  \"node_names\":['n1','n2'],\n",
    "                  \"node_descriptions\":[\"Pandas Data Frame\",\"AsciiDataTable\"],\n",
    "                  \"current_node\":'n1',\n",
    "                  \"state\":[1,0],\n",
    "                  \"data\":data_frame,\n",
    "                  \"edge_2_to_1\":AsciiDataTable_to_DataFrame,\n",
    "                  \"edge_1_to_2\":DataFrame_to_AsciiDataTable\n",
    "                 }\n",
    "rect_graph=Graph(**graph_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving n1 -> n2\n",
      "moving n2 -> n1\n",
      "moving n1 -> n2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rect_graph.is_graph_isomorphic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving n2 -> n1\n",
      "moving n1 -> n2\n"
     ]
    }
   ],
   "source": [
    "rect_graph.move_to_node(\"n2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print rect_graph.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def edge_1_to_3(pandas_data_frame):\n",
    "    pandas_data_frame.to_hdf(\"Test.hdf\",\"table\")\n",
    "    return \"Test.hdf\"\n",
    "def edge_3_to_1(hdf_file_name):\n",
    "    df=pandas.read_hdf(hdf_file_name,\"table\")\n",
    "    return df\n",
    "\n",
    "rect_graph.add_node(\"n3\",\"n1\",edge_1_to_3,\"n1\",edge_3_to_1)\n",
    "rect_graph.node_descriptions.append(\"HDF File\")\n",
    "\n",
    "def edge_4_to_2(xml_table):\n",
    "    \n",
    "    table=AsciiDataTable(None,\n",
    "                         column_names=xml_table.attribute_names,\n",
    "                         data=xml_table.data)\n",
    "    return table\n",
    "\n",
    "def edge_2_to_4(data_table):\n",
    "    xml=AsciiDataTable_to_XMLDataTable(data_table)\n",
    "    return xml\n",
    "\n",
    "rect_graph.add_node(\"n4\",\"n2\",edge_2_to_4,\"n2\",edge_4_to_2)\n",
    "rect_graph.node_descriptions.append(\"XML Data Table\")\n",
    "\n",
    "# Need to add XML File and Html File using save and save_HTML()\n",
    "\n",
    "\n",
    "def edge_1_to_5(pandas_data_frame,file_name=\"Test.xlsx\"):\n",
    "    pandas_data_frame.to_excel(file_name,index=False)\n",
    "    return file_name\n",
    "\n",
    "def edge_5_to_1(excel_file_name):\n",
    "    df=pandas.read_excel(excel_file_name)\n",
    "    return df\n",
    "\n",
    "rect_graph.add_node(\"n5\",\"n1\",edge_1_to_5,\"n1\",edge_5_to_1)\n",
    "rect_graph.node_descriptions.append(\"Excel File\")\n",
    "\n",
    "def edge_1_to_6(pandas_data_frame):\n",
    "    html=pandas_data_frame.to_html(index=False)\n",
    "    return html\n",
    "\n",
    "def edge_6_to_1(html_string):\n",
    "    list_df=pandas.read_html(html_string)\n",
    "    return list_df[0]\n",
    "\n",
    "rect_graph.add_node(\"n6\",\"n1\",edge_1_to_6,\"n1\",edge_6_to_1)\n",
    "rect_graph.node_descriptions.append(\"HTML String\")\n",
    "\n",
    "# Note a lot of the pandas reading and writing cause float64 round off errors\n",
    "# applymap(lambda x: np.around(x,10) any all float fields will fix this\n",
    "# also the column names move about in order\n",
    "\n",
    "def edge_1_to_7(pandas_data_frame):\n",
    "    json=pandas_data_frame.to_json(\"test.json\",orient='records')\n",
    "    return \"test.json\"\n",
    "\n",
    "def edge_7_to_1(json_file_name):\n",
    "    data_frame=pandas.read_json(json_file_name,orient='records')\n",
    "    return data_frame\n",
    "\n",
    "rect_graph.add_node(\"n7\",\"n1\",edge_1_to_7,\"n1\",edge_7_to_1)\n",
    "rect_graph.node_descriptions.append(\"JSON File\")\n",
    "\n",
    "def edge_1_to_8(pandas_data_frame):\n",
    "    json=pandas_data_frame.to_json(orient='records')\n",
    "    return json\n",
    "\n",
    "def edge_8_to_1(json_string):\n",
    "    data_frame=pandas.read_json(json_string,orient='records')\n",
    "    return data_frame\n",
    "\n",
    "rect_graph.add_node(\"n8\",\"n1\",edge_1_to_8,\"n1\",edge_8_to_1)\n",
    "rect_graph.node_descriptions.append(\"JSON String\")\n",
    "\n",
    "def edge_1_to_9(pandas_data_frame,file_name=\"test.csv\"):\n",
    "    json=pandas_data_frame.to_csv(file_name,index=False)\n",
    "    return file_name\n",
    "\n",
    "def edge_9_to_1(csv_file_name):\n",
    "    data_frame=pandas.read_csv(csv_file_name)\n",
    "    return data_frame\n",
    "\n",
    "rect_graph.add_node(\"n9\",\"n1\",edge_1_to_9,\"n1\",edge_9_to_1)\n",
    "rect_graph.node_descriptions.append(\"CSV File\")\n",
    "\n",
    "def edge_2_to_10(ascii_data_table,file_name=\"test.mat\"):\n",
    "    matlab_data_dictionary={\"data\":ascii_data_table.data,\"column_names\":ascii_data_table.column_names}\n",
    "    savemat(file_name,matlab_data_dictionary)\n",
    "    return file_name\n",
    "\n",
    "def edge_10_to_2(matlab_file_name):\n",
    "    matlab_data_dictionary=loadmat(matlab_file_name)\n",
    "    ascii_data_table=AsciiDataTable(None,\n",
    "                                    column_names=map(lambda x: x.rstrip().lstrip(),\n",
    "                                                     matlab_data_dictionary[\"column_names\"].tolist()),\n",
    "                                     data=matlab_data_dictionary[\"data\"].tolist())\n",
    "    return ascii_data_table\n",
    "\n",
    "rect_graph.add_node(\"n10\",\"n2\",edge_2_to_10,\"n2\",edge_10_to_2)\n",
    "rect_graph.node_descriptions.append(\"Matlab File\")\n",
    "\n",
    "def edge_7_to_4(json_file_string):\n",
    "    data_dictionary_list=json.load(open(json_file_string,'r'))\n",
    "    xml=DataTable(None,data_dictionary={\"data\":data_dictionary_list})\n",
    "    return xml\n",
    "rect_graph.add_edge(\"n7\",\"n4\",edge_7_to_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving n2 -> n1\n",
      "moving n1 -> n2\n",
      "moving n2 -> n1\n",
      "moving n1 -> n3\n",
      "moving n3 -> n1\n",
      "moving n1 -> n2\n",
      "moving n2 -> n4\n",
      "moving n4 -> n2\n",
      "moving n2 -> n1\n",
      "moving n1 -> n5\n",
      "moving n5 -> n1\n",
      "moving n1 -> n6\n",
      "moving n6 -> n1\n",
      "moving n1 -> n7\n",
      "moving n7 -> n1\n",
      "moving n1 -> n8\n",
      "moving n8 -> n1\n",
      "moving n1 -> n9\n",
      "moving n9 -> n1\n",
      "moving n1 -> n2\n",
      "moving n2 -> n10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rect_graph.is_graph_isomorphic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print rect_graph.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=rect_graph.get_path(\"n3\",\"n2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving n3 -> n1\n"
     ]
    },
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"C:\\aroot\\work\\hdf5-1.8.15-patch1\\src\\H5F.c\", line 604, in H5Fopen\n    unable to open file\n  File \"C:\\aroot\\work\\hdf5-1.8.15-patch1\\src\\H5Fint.c\", line 1085, in H5F_open\n    unable to read superblock\n  File \"C:\\aroot\\work\\hdf5-1.8.15-patch1\\src\\H5Fsuper.c\", line 277, in H5F_super_read\n    file signature not found\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'test.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bfbd5bdf9482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrect_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-9ac3ef414747>\u001b[0m in \u001b[0;36mmove_to\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"moving {0} -> {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin_node\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;31m#print self.data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[1;31m#print self.data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'end_node'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-accf40cd7a3b>\u001b[0m in \u001b[0;36medge_3_to_1\u001b[1;34m(hdf_file_name)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"Test.hdf\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0medge_3_to_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdf_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdf_file_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\pytables.pyc\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(path_or_buf, key, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;31m# can't auto open/close if we are using an iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;31m# so delegate to the iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mstore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[0mauto_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\pytables.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\io\\pytables.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'can not be written'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tables\\file.pyc\u001b[0m in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;31m# Finally, create the File instance, and return it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[0mopenFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\tables\\file.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[1;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables\\hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new (tables\\hdf5extension.c:5458)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"C:\\aroot\\work\\hdf5-1.8.15-patch1\\src\\H5F.c\", line 604, in H5Fopen\n    unable to open file\n  File \"C:\\aroot\\work\\hdf5-1.8.15-patch1\\src\\H5Fint.c\", line 1085, in H5F_open\n    unable to read superblock\n  File \"C:\\aroot\\work\\hdf5-1.8.15-patch1\\src\\H5Fsuper.c\", line 277, in H5F_super_read\n    file signature not found\n\nEnd of HDF5 error back trace\n\nUnable to open/create file 'test.mat'"
     ]
    }
   ],
   "source": [
    "rect_graph.move_to(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml=AsciiDataTable_to_XMLDataTable(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xml.to_tuple_list(xml.get_attribute_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xml.to_list(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xml.attribute_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xml.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=rect_graph.get_path(\"n5\",\"n1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.path_length(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n1\")\n",
    "for node in rect_graph.node_names:\n",
    "    path=rect_graph.get_path(\"n1\",node)\n",
    "    print(\"The length of the path n1-> {0} in s is {1}\".format(node,rect_graph.path_length(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html=rect_graph.data.to_html(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pandas.read_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table=OnePortCalrepModel(os.path.join(TESTS_DIRECTORY,'700437.asc'))\n",
    "rect_graph.set_state(\"n2\",table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print rect_graph.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def move_and_print(end_node_number):\n",
    "    node=rect_graph.node_names[end_node_number]\n",
    "    rect_graph.move_to_node(node)\n",
    "    print(\"*\"*80)\n",
    "    print(\"{0}\".format(rect_graph.node_descriptions[end_node_number])+\" {0}\".format(rect_graph.state))\n",
    "    print(\"*\"*80)\n",
    "    print rect_graph.data\n",
    "    \n",
    "interact(move_and_print,end_node_number=(0,len(rect_graph.node_names)-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json=data_frame.to_json(\"test.json\",orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string=data_frame.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df=pandas.read_json(json_string,orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df=pandas.read_json(\"test.json\",orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#str(table.get_data_dictionary_list())\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.node_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "test_list=json.load(open(\"test.json\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_xml=DataTable(None,**{\"data_dictionary\":{\"data\":test_list}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print text_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print rect_graph.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat,loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savemat(\"data.mat\",{\"data\":table.data,\"column_names\":table.column_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=loadmat(\"data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_table=AsciiDataTable(None,column_names=map(lambda x: x.rstrip().lstrip(),data[\"column_names\"].tolist()),\n",
    "                         data=data[\"data\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rect_graph.move_to_node(\"n4\")\n",
    "xml=rect_graph.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import odo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame.dtypes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"test.db\")\n",
    "conn.execute(\"create table data\")\n",
    "odo.odo(data_frame,'sqlite:///test.db::data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The self.metadata[\"Device_Id\"] variable is 700437\n"
     ]
    }
   ],
   "source": [
    "one_port=OnePortCalrepModel(os.path.join(TESTS_DIRECTORY,'700437.asc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_port.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_port.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Analysis_Date': '16-Oct-15', 'Device_Id': '700437'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_port.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header\n",
      "column_names\n",
      "data\n",
      "footer\n",
      "inline_comments\n",
      "metadata\n"
     ]
    }
   ],
   "source": [
    "for element in one_port.elements:\n",
    "    print element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_table=pandas.DataFrame(one_port.header,columns=[\"Header_Line_Content\"])\n",
    "data_table=pandas.DataFrame(one_port.data,columns=one_port.column_names)\n",
    "footer_table=pandas.DataFrame(one_port.footer,columns=[\"Footer_Line_Content\"])\n",
    "inline_comments=pandas.DataFrame(one_port.footer,columns=[\"Line\",\"Location\",\"Comment\"])\n",
    "metadata_table=pandas.DataFrame([[key,value] for key,value in one_port.metadata.iteritems() ], \n",
    "                                columns=[\"Property\",\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def AsciiDataTable_to_DataFrame_dict(AsciiDataTable):\n",
    "    \"\"\"Converts an AsciiDataTable to a dictionary of pandas.DataFrame s\"\"\"\n",
    "    output_dict={}\n",
    "    for element in AsciiDataTable.elements:\n",
    "        #print(\"{0} is {1}\".format('element',element))\n",
    "        if AsciiDataTable.__dict__[element]:\n",
    "            if re.search('header',element,re.IGNORECASE):\n",
    "                header_table=pandas.DataFrame(AsciiDataTable.header,columns=[\"Header_Line_Content\"])\n",
    "                output_dict[\"Header\"]=header_table\n",
    "            # needs to be before data search    \n",
    "            elif re.search('meta',element,re.IGNORECASE):\n",
    "                #print(\"{0} is {1}\".format('element',element))\n",
    "                metadata_table=pandas.DataFrame([[key,value] for key,value in AsciiDataTable.metadata.iteritems()], \n",
    "                                columns=[\"Property\",\"Value\"])\n",
    "                output_dict[\"Metadata\"]=metadata_table    \n",
    "            elif re.search('data|^meta',element,re.IGNORECASE):\n",
    "                data_table=pandas.DataFrame(AsciiDataTable.data,columns=AsciiDataTable.column_names)\n",
    "                output_dict[\"Data\"]=data_table\n",
    "                \n",
    "            elif re.search('footer',element,re.IGNORECASE):\n",
    "                footer_table=pandas.DataFrame(AsciiDataTable.footer,columns=[\"Footer_Line_Content\"])\n",
    "                output_dict[\"Footer\"]=footer_table\n",
    "                \n",
    "            elif re.search('comment',element,re.IGNORECASE):\n",
    "                inline_comments=pandas.DataFrame(AsciiDataTable.footer,columns=[\"Line\",\"Location\",\"Comment\"])\n",
    "                output_dict[\"Comments\"]=inline_comments\n",
    "                \n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element is header\n",
      "element is column_names\n",
      "element is data\n",
      "element is footer\n",
      "element is inline_comments\n",
      "element is metadata\n",
      "element is metadata\n"
     ]
    }
   ],
   "source": [
    "panda_dict=AsciiDataTable_to_DataFrame_dict(one_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysis_Date</td>\n",
       "      <td>16-Oct-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Device_Id</td>\n",
       "      <td>700437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Property      Value\n",
       "0  Analysis_Date  16-Oct-15\n",
       "1      Device_Id     700437"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda_dict[\"Metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "panda_dict[\"Data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataFrame_dict_to_excel(DataFrame_dict,excel_file_name=\"Test.xlsx\"):\n",
    "    \"\"\"Converts a dictionary of pandas DataFrames to a single excel file with sheet names\n",
    "    determined by keys\"\"\"\n",
    "    # sort the keys so that they will display in the same order\n",
    "    writer = pandas.ExcelWriter(excel_file_name)\n",
    "    keys=sorted(DataFrame_dict.keys())\n",
    "    for key in keys:\n",
    "        #print key\n",
    "        DataFrame_dict[key].to_excel(writer,sheet_name=key,index=False)\n",
    "        writer.close()\n",
    "    return excel_file_name\n",
    "\n",
    "def excel_to_DataFrame_dict(excel_file_name):\n",
    "    \"\"\"Reads an excel file into a dictionary of data frames\"\"\"\n",
    "    data_frame_dictionary=pandas.read_excel(excel_file_name,sheetname=None)\n",
    "    return data_frame_dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataFrame_dict_to_excel(panda_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dict=pandas.read_excel(\"Test.xlsx\",sheetname=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dict[\"Header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_table=TwoPortRawModel(os.path.join(TESTS_DIRECTORY,'TestFileTwoPortRaw.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element is header\n",
      "element is column_names\n",
      "element is data\n",
      "element is footer\n",
      "element is inline_comments\n",
      "element is metadata\n",
      "element is metadata\n"
     ]
    }
   ],
   "source": [
    "test_dict=AsciiDataTable_to_DataFrame_dict(raw_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Header', 'Data', 'Metadata']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Connector_Type_Calibration</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number_Connects</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connector_Type_Measurement</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number_Repeats</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operator</td>\n",
       "      <td>BFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number_Frequencies</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Start_Frequency</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Measurement_Date</td>\n",
       "      <td>9 Sep 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Program_Used</td>\n",
       "      <td>MEASLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Measurement_Type</td>\n",
       "      <td>2-port</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>System_Id</td>\n",
       "      <td>HP8510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nbs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Device_Id</td>\n",
       "      <td>CTN208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Measurement_Time</td>\n",
       "      <td>10:31:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Program_Revision</td>\n",
       "      <td>150122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Port_Used</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Calibration_Date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Device_Description</td>\n",
       "      <td>CHECK STANDARD 20 dB ATTEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Calibration_Name</td>\n",
       "      <td>c050211.a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>System_Letter</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Property                       Value\n",
       "0   Connector_Type_Calibration                            \n",
       "1              Number_Connects                           3\n",
       "2   Connector_Type_Measurement                           N\n",
       "3               Number_Repeats                           1\n",
       "4                     Operator                         BFR\n",
       "5           Number_Frequencies                          53\n",
       "6              Start_Frequency                           7\n",
       "7             Measurement_Date                  9 Sep 2015\n",
       "8                 Program_Used                      MEASLP\n",
       "9             Measurement_Type                      2-port\n",
       "10                   System_Id                      HP8510\n",
       "11                         Nbs                           4\n",
       "12                   Device_Id                      CTN208\n",
       "13            Measurement_Time                    10:31:55\n",
       "14            Program_Revision                      150122\n",
       "15                   Port_Used                           1\n",
       "16            Calibration_Date                            \n",
       "17          Device_Description  CHECK STANDARD 20 dB ATTEN\n",
       "18            Calibration_Name                  c050211.a2\n",
       "19               System_Letter                           L"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[\"Metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Line_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP8510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-port</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9 Sep 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10:31:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MEASLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c050211.a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CHECK STANDARD 20 dB ATTEN                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CTN208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Header_Line_Content\n",
       "0                                        HP8510      \n",
       "1                                                  L \n",
       "2                                                    \n",
       "3                                             N      \n",
       "4                                     2-port         \n",
       "5                                      9 Sep 2015    \n",
       "6                                          10:31:55  \n",
       "7                                          MEASLP    \n",
       "8                                          150122    \n",
       "9                                          BFR       \n",
       "10                                    c050211.a2     \n",
       "11                                                   \n",
       "12                                                  1\n",
       "13                                                  3\n",
       "14                                                  1\n",
       "15                                                  4\n",
       "16                                                 53\n",
       "17                                                  7\n",
       "18  CHECK STANDARD 20 dB ATTEN                    ...\n",
       "19                               CTN208              "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[\"Header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
