{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multidimensional Visualization of Calibration Comparisions\n",
    "\n",
    "## Abstract\n",
    "   Today there exists many different approaches for creating corrections for the modern Vector Network Analyzer. Each of these methods have relative advantages based on their estimated uncertainties, measurement artifact requirements, frequency converage, and complexity. The breadth of correction methods are becoming more accesible to researchers as tools provided by VNA vendors and national metrology laboratories have become more numerous and more accomidating to the varied methods. These tools are also offering better uncertainty analysis regarding the correction techniques of choice. In order to compare these different methods, researchers have historically turned to worst cast estimates or bench mark two tier calibrations comparing the calibration of interest to the T-R-L method. Here we present a way to visualize two calibrations with estimated uncertainties over a complex plane.\n",
    "\n",
    "\n",
    "## Methods and Purposed Figures\n",
    "\n",
    "1. A plot comparing worst case metric in Rs and TRL (standard radical)\n",
    "2. A figure showing typcal standards on the complex plane, the equivelent of the worst case in the plane and a full calibration on the plane.\n",
    "3. a multidimension comparision of TRL, RS, OSLT and OSL unknown thru\n",
    "\n",
    "## Corollary\n",
    "1. The comparision of two sparameters with uncertainty using Standard Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Code.Utils.Names\n",
      "Importing Code.DataHandlers.NISTModels\n",
      "The module smithplot was not found,please put it on the python path\n",
      "Importing Code.DataHandlers.GeneralModels\n",
      "Importing Code.DataHandlers.TouchstoneModels\n",
      "The module smithplot was not found,please put it on the python path\n",
      "Importing Code.DataHandlers.XMLModels\n",
      "Importing Code.DataHandlers.RadiCALModels\n",
      "Importing Code.DataHandlers.ZipModels\n",
      "Importing Code.DataHandlers.Translations\n",
      "The module pdfkit was not found or had an error,please check module or put it on the python path use pip install pdfkit and also install wkhtmltopdf\n",
      "Importing Code.DataHandlers.StatistiCALModels\n",
      "Importing Code.DataHandlers.MUFModels\n",
      "Importing Code.Analysis.SParameter\n",
      "The module pdfkit was not found or had an error,please check module or put it on the python path use pip install pdfkit and also install wkhtmltopdf\n",
      "Importing Code.InstrumentControl.Instruments\n",
      "Importing Code.InstrumentControl.Experiments\n"
     ]
    }
   ],
   "source": [
    "from pyMeasure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-ecee3b42e170>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-ecee3b42e170>\"\u001b[1;36m, line \u001b[1;32m35\u001b[0m\n\u001b[1;33m    \"table_1_uncertainty_type\":\"table\",\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class StandardErrorModel(AsciiDataTable):\n",
    "    \"\"\"Model that stores data for standard error in the form [[independent_variable,SEValue1,..,SEValueN]..]\n",
    "    See function `pyMeasure.Code.Analysis.Uncertainty.standard_error_data_table`\"\"\"\n",
    "    def __init__(self,file_path,**options):\n",
    "        \"\"\"Intializes the StandardErrorModel Class\"\"\"\n",
    "        AsciiDataTable.__init__(self,file_path,**options)\n",
    "class StandardErrorError(Exception):\n",
    "    \"Error class for standard error functions and classes\"\n",
    "    pass\n",
    "# Comparison of two curves where at least one has error\n",
    "# possible error types: table, constant, fractional, functional and None\n",
    "def standard_error_data_table(table_1,table_2,**options):\n",
    "    \"\"\"standard error data table takes two tables and creates a table that is the standard error of the two tables, \n",
    "    at least one table must have uncertainties associated with it. The input tables are assumed to have data\n",
    "    in the form [[x, y1, y2,...]..] Uncertatinties can be specified as a column name in the repective \n",
    "    table, fractional, constant, or a function of the values. The returned table is an object\n",
    "    of the class StandardErrorModel(AsciiDataTable) that has data in the form \n",
    "    [[independent_varaible,SEValue1,SEValue2...]...] where column names are formed by \n",
    "    appending SE to the value column names. To plot the table use result.show()\n",
    "    \"\"\"\n",
    "    defaults={}\n",
    "    error_options={\"independent_variable_column_name\":\"Frequency\",\n",
    "                  \"value_column_names\":['magS11','argS11','magS12','argS12','magS21',\n",
    "                                                'argS21','magS22','argS22'],\n",
    "                  \"table_1_uncertainty_column_names\":['uMgS11','uAgS11','uMgS12','uAgS12',\n",
    "                                                      'uMgS21','uAgS21','uMgS22','uAgS22'],\n",
    "                  \"table_2_uncertainty_column_names\":['uMgS11','uAgS11','uMgS12','uAgS12',\n",
    "                                                      'uMgS21','uAgS21','uMgS22','uAgS22'],\n",
    "                   \"uncertainty_table_1\":None,\n",
    "                   \"uncertainty_table_2\":None,\n",
    "                   \"uncertainty_function_table_1\":None,\n",
    "                   \"uncertainty_function_table_2\":None,\n",
    "                   \"uncertainty_function\":None,\n",
    "                   \"uncertainty_type\":None\n",
    "                   \"table_1_uncertainty_type\":\"table\",\n",
    "                   \"table_2_uncertainty_type\":None,\n",
    "                   \"expansion_factor\":1,\n",
    "                   'debug':True\n",
    "                  }\n",
    "    \n",
    "    for key,value in defaults.itteritems():\n",
    "        error_options[key]=value\n",
    "    for key,value in options.itteritems():\n",
    "        error_options[key]=value\n",
    "    # Begin by checking at least one table has an error associated with it\n",
    "    if error_options[\"table_1_uncertainty_type\"] is None and error_options[\"table_2_uncertainty_type\"] is None:\n",
    "        raise StandardErrorError(\"Undefined Error For Both Tables: Define at least one of\"\n",
    "                                 \"table_1_uncertainty_type or table_2_uncertainty_type to be a value other than None\")\n",
    "    if error_options[\"expansion_factor\"]:\n",
    "        expansion_factor=float(error_options[\"expansion_factor\"])\n",
    "    else:\n",
    "        expansion_factor=1\n",
    "    # first find a unique list of the independent variable for both curves\n",
    "    if error_options[\"debug\"]:\n",
    "        begin_time=datetime.datetime.utcnow()\n",
    "        print(\"started finding intersection of\" \n",
    "              \"table_1[{0}] and table_2[{1}] at {3}\".format(error_options[\"independent_variable_column_name\"],\n",
    "                                                           error_options[\"independent_variable_column_name\"],\n",
    "                                                           begin_time))\n",
    "    x_set_table_1=set(table_1[error_options[\"independent_variable_column_name\"]])\n",
    "    x_set_table_2=set(table_2[error_options[\"independent_variable_column_name\"]])\n",
    "    unique_x=sorted(list(x_set_table_1.intersection(x_set_table_2)))\n",
    "    if error_options[\"debug\"]:\n",
    "        end_time=datetime.datetime.utcnow()\n",
    "        print(\"finished finding intersection at {1}\".format(end_time))\n",
    "        delta_time=end_time-begin_time\n",
    "        print(\"it took {0} to find the intersection that contained {1} points\".format(delta_time,len(unique_x)))\n",
    "    if not unique_x:\n",
    "        raise StandardErrorError(\"No points in the intersection, please either interpolate one data set or compare\"\n",
    "                                 \"with another data set\")\n",
    "    \n",
    "    # next build the new data set \n",
    "    out_data=[]\n",
    "    x_column_index_table_1=table_1.column_names.pos(error_options[\"table_1_independent_variable\"])\n",
    "    x_column_index_table_2=table_2.column_names.pos(error_options[\"table_2_independent_variable\"])\n",
    "    # we choose the row by using unique_x\n",
    "    for x_value in unique_x:\n",
    "        # here if there are multiple values for x_value we ignore them\n",
    "        table_1_row=filter(lambda x: x[x_column_index_table_1]==x_value,table_1.data)[0]\n",
    "        # we begin a new_row\n",
    "        table_2_rows=filter(lambda x: x[x_column_index_table_1]==x_value,table_2.data)\n",
    "        for table_1_row in table_2_rows:\n",
    "            new_row=[x_value]\n",
    "            for column_index,column_name in enumerate(error_options[\"value_column_names\"]):\n",
    "                value_1_column_selector=table_1.column_names.pos(column_name)\n",
    "                value_2_column_selector=table_2.column_names.pos(column_name)\n",
    "                value_1=table_1_row[value_1_column_selector]\n",
    "                value_2=table_2_row[value_2_column_selector]\n",
    "                # now we assign the error to value 1\n",
    "                if re.search(\"table|list\",error_options[\"table_1_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_1_column_selector=table_1.column_names.pos(error_options[\"table_1_uncertainty_column_names\"][column_index])\n",
    "                    error_1=table_1_row[error_1_column_selector]\n",
    "                elif re.search(\"con|fixed\",error_options[\"table_1_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_1=float(error_options[\"uncertainty_table_1\"])\n",
    "                elif re.search(\"fract\",error_options[\"table_1_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_1=float(error_options[\"uncertainty_table_1\"])*value_1\n",
    "                elif re.search(\"func\",error_options[\"table_1_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_1=error_options[\"uncertainty_table_1_function\"](value_1)\n",
    "                else:\n",
    "                    error_1=0\n",
    "                # now the same for table 2\n",
    "                if re.search(\"table|list\",error_options[\"table_2_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_2_column_selector=table_2.column_names.pos(error_options[\"table_2_uncertainty_column_names\"][column_index])\n",
    "                    error_2=table_2_row[error_2_column_selector]\n",
    "                elif re.search(\"con|fixed\",error_options[\"table_2_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_2=float(error_options[\"uncertainty_table_2\"])\n",
    "                elif re.search(\"fract\",error_options[\"table_2_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_2=float(error_options[\"uncertainty_table_2\"])*value_2\n",
    "                elif re.search(\"func\",error_options[\"table_2_uncertainty_type\"],re.IGNORECASE):\n",
    "                    error_2=error_options[\"uncertainty_table_2_function\"](value_2)\n",
    "                else:\n",
    "                    error_2=0\n",
    "                # now calculate the value and append\n",
    "                \n",
    "                standard_error=(value_1-value_2)/(expansion_factor*math.sqrt(error_1**2+error_2**2))\n",
    "                new_row.append(standard_error)\n",
    "            out_data.append(new_row)\n",
    "        # now we handle the standard error table creation\n",
    "    standard_error_column_names=[error_options[\"independent_variable_column_name\"]]\n",
    "    for column_name in error_options[\"value_column_names\"]:\n",
    "        standard_error_column_names.append(\"SE\"+column_name)\n",
    "    error_options[\"column_names\"]=standard_error_column_names[:]\n",
    "    error_options[\"column_types\"]=['float' for column in  standard_error_column_names[:]]\n",
    "    error_options[\"data\"]=out_data[:]\n",
    "    out_table=StandardErrorModel(None,**error_options)\n",
    "    return out_table\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
